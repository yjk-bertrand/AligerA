#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
#    Copyright (C) 2019 Yann J.K. BERTRAND: yjk_bertrand@ybertrand.org
#       All rights reserved.
#
"""
    Functions used by the AligerA pipeline tool to trim an alignment out of sparsely
    overlapping flanking regions and highly gapped columns.
    Finding flanking limits uses an interval search tree algorithm and removing 
    mostly empty columns uses a sliding window.
    The difference with the step 2 workflow is that step 6 also search and delete
    small fragments that have low similarity to the other sequences and that are 
    separated from longer sequences by stretches of ambiguous sequences. These small
    sequences have either not been removed during step 3 because they are too short or 
    they have been generated by step 3 that has removed large regions, leaving small
    poorly aligned fragments between these large regions.
"""
__version__ = "1.3"

# =======================================================================================
#               IMPORTS
# =======================================================================================

import sys
import shutil

from Bio import SeqIO, AlignIO
from Bio.SeqRecord import SeqRecord
from Bio.Alphabet import IUPAC
from Bio.Seq import Seq

try:
    from aligera_scripts.find_limits import FindLimits
except:
    from find_limits import FindLimits

try:
    from STEP2_scripts import find_gapped_columns
except:
    from aligera_scripts.STEP2_scripts import find_gapped_columns

# =======================================================================================
#                FUNCTIONS
# =======================================================================================


def clean_small_frag(trim_align, len_frag, len_gaps, len_tiny, align_length):
    """
    Find and remove isolated sequences fragments smaller than 'len_frag'
    and having flanking gaps longer than 'len_gaps'
    """
    len_align = align_length
    clean_records = []
    for record in trim_align:
        seq = str(record.seq)
        idx_no_gap = []
        for idx, base in enumerate(seq):
            if base not in ("-", "N", "n"):
                idx_no_gap.append(idx)
        clusters_bases = []
        if idx_no_gap:
            initial = idx_no_gap[0]
            stack = idx_no_gap[1:]
            start = initial
            while stack:
                next_valid = initial + 1
                if next_valid != stack[0] or next_valid == idx_no_gap[-1]:
                    clusters_bases.append((start, next_valid))
                    initial = stack[0]
                    stack = stack[1:]
                    start = initial
                else:
                    initial = stack[0]
                    stack = stack[1:]

            L_index_item = clusters_bases
            start_1 = L_index_item[0][0]
            end_1 = L_index_item[0][1]
            stack = L_index_item[1:]
            clusters_bases_updated = []
            if not stack:
                clusters_bases_updated = clusters_bases
            while stack:
                start_2 = stack[0][0]
                end_2 = stack[0][1]
                if end_2 - start_1 <= len_frag:
                    stack = stack[1:]
                    start_1 = start_1
                    end_1 = end_2
                else:
                    clusters_bases_updated.append((start_1, end_1))
                    stack = stack[1:]
                    start_1 = start_2
                    end_1 = end_2
                if len(stack) == 0:
                    clusters_bases_updated.append((start_1, end_1))

            slist = list(seq)
            for item in [
                x for x in clusters_bases_updated if (x[1] - x[0]) <= len_frag
            ]:
                #  Remove a seq fragment if its length is under the threshold
                #  and if it is flanked by stretches of "-" that are longer
                #  than the pre-defined length.
                #  When the fragment is placed near the alignment border,
                #   only the large flanking stretch of "-" is counted.

                slice_seq_left = seq[item[0] - len_gaps : item[0]]
                flanking_gaps_left = (
                    slice_seq_left.count("-")
                    + slice_seq_left.count("N")
                    + slice_seq_left.count("n")
                )
                slice_seq_right = seq[item[1] + 1 : item[1] + 1 + len_gaps]
                flanking_gaps_right = (
                    slice_seq_right.count("-")
                    + slice_seq_right.count("N")
                    + slice_seq_right.count("n")
                )
                if (
                    (flanking_gaps_left >= len_gaps and flanking_gaps_right >= len_gaps)
                    or (
                        item[0] in range(0, len_gaps)
                        and flanking_gaps_right >= len_gaps
                    )
                    or (
                        item[1] in range(len_align - len_gaps, len_align + 1)
                        and flanking_gaps_left >= len_gaps
                    )
                ):

                    for i in range(item[0], item[1] + 1):
                        slist[i] = "-"

                elif (item[1] - item[0]) <= len_tiny:
                    # Remove tiny fragments irrespectively
                    # of the number of flanking "-"s.
                    for i in range(item[0], item[1] + 1):
                        slist[i] = "-"
            new_seq = "".join(slist).upper().replace("N", "-")
            new_rec = SeqRecord(
                Seq(new_seq, IUPAC.IUPACAmbiguousDNA()),
                name=record.name,
                id=record.id,
                description="",
            )
            clean_records.append(new_rec)
    return clean_records


def trim_clean(fasta, cfg, **kargs):
    """
    Main function for STEP6:
    interp. 
        ungap_proportion (float)    Minimum proportion of non gap positions to 
                                    be considered during limit search.
        min_aa_proportion (float)   Minimum proportion of conserved aa in the column
                                    for the column to be considered during limit search.
        max_gap_proportion (float)  Maximum proportion of gaps in the column. 
                                    Columns that have higher proportions of gap are 
                                    removed.
        window_length (int)         length of the window in nucleotides that is 
                                    translated in order to search for conserved 
                                    consecutive columns of nucleotides.
        lenght_small_fragment (int) Maximum length of isolated fragments to remove.
        length_flanking_gaps (int)  Minimum length of ambiguous regions flanking a 
                                    small fragment to be removed. If the small fragment
                                    is near the beginning or end or the alignment, this
                                    length is relaxed between the border and the 
                                    fragment.
        length_tiny_fragments (int) Length of small fragments that are removed 
                                    irrespectively of the length of
                                    ambiguous regions flanking them.
                                    
    """

    window_length = (cfg["window_length"] // 3) * 3
    if window_length < 3:
        exception = "[Error] Problem window length < 3 \n\
        Exiting..."
        raise Exception(exception)
        sys.exit()
    in_format = cfg["input_format"]
    out_suffix = cfg["output_suffix"]
    out_folder = cfg["output_folder"]
    window_length = cfg["window_length"]
    len_frag = cfg["lenght_small_fragment"]
    len_gaps = cfg["length_flanking_gaps"]
    len_tiny = cfg["length_tiny_fragments"]
    basename = fasta.split(in_format)[0]
    try:
        align = AlignIO.read(fasta, "fasta")
    except:
        exception = "[Error] Problem opening fasta alignment {}\n\
        Are all sequences the same length?".format(
            fasta
        )
        raise Exception(exception)
        return exception

    n_seq = len(align)
    if n_seq < 3:
        s_i = "STEP6 Done with fasta: {}".format(fasta)
        s_d = "No transformation performed on fasta {0}\n\
        which only contains {1} sequences".format(
            fasta, n_seq
        )
        return (s_i, s_d)

    try:
        FL = FindLimits(align, **cfg)
    except Exception as ex:
        template = "An exception of type {0} occurred when trying to\
 instantiate FindLimit object. Arguments:\n{1!r}"
        message = template.format(type(ex).__name__, ex.args)
        print(message)
        sys.exit(0)

    FL.findFragments()
    FL.findLimits()

    align_length = align.get_alignment_length()
    start = FL.start
    end = FL.end
    if start > end:
        exception = "[Error] Problem with finding start/end \
        for fasta {0}; Start: {1}, End: {2}".format(
            fasta, start, end
        )
        raise Exception(exception)
        start = 0
        end = align_length

    new_align = align[:, start:end]
    trimmed_align = find_gapped_columns(new_align, cfg)
    try:
        clean_align = clean_small_frag(
            trimmed_align, len_frag, len_gaps, len_tiny, align_length
        )
    except:
        Exception("problem with fasta {}".format(fasta))
        sys.exit()
    SeqIO.write(clean_align, basename + out_suffix + ".fasta", "fasta")
    shutil.move(basename + out_suffix + ".fasta", out_folder)

    s_i = "STEP6 Done with fasta: {}".format(fasta)
    s_d = "start: {0} end: {1}".format(start, end)
    return (s_i, s_d)
